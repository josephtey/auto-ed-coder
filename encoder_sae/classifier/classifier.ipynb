{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/steering-collab/LLMonade/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_mutation' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.sae_actions import load_pretrained_sae, sae_featurize_data \n",
    "from shared.models import MiniPileDataset\n",
    "from shared.features import Feature, FeatureSample\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/steering-collab/LLMonade/.venv/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "# Load SAE\n",
    "sae = load_pretrained_sae(\"../training_sae/saes/spam_messages_test_20241203_013809\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featurize train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_features(feature_dir):\n",
    "    \"\"\"Load features from JSON files and convert to Feature objects\"\"\"\n",
    "    # Get all JSON files from the features directory\n",
    "    feature_files = glob.glob(os.path.join(feature_dir, \"*.json\"))\n",
    "\n",
    "    # Load all feature JSONs into Feature objects\n",
    "    features = []\n",
    "    for file in feature_files:\n",
    "        with open(file) as f:\n",
    "            feature_dict = json.load(f)\n",
    "            \n",
    "            # Convert samples to FeatureSample objects\n",
    "            high_act_samples = [\n",
    "                FeatureSample(text=s[\"text\"], act=s[\"act\"]) \n",
    "                for s in feature_dict[\"high_act_samples\"]\n",
    "            ]\n",
    "            low_act_samples = [\n",
    "                FeatureSample(text=s[\"text\"], act=s[\"act\"])\n",
    "                for s in feature_dict[\"low_act_samples\"] \n",
    "            ]\n",
    "            \n",
    "            feature = Feature(\n",
    "                index=feature_dict[\"index\"],\n",
    "                label=feature_dict[\"label\"],\n",
    "                attributes=feature_dict[\"attributes\"],\n",
    "                reasoning=feature_dict[\"reasoning\"],\n",
    "                density=feature_dict[\"density\"],\n",
    "                confidence=feature_dict[\"confidence\"],\n",
    "                high_act_samples=high_act_samples,\n",
    "                low_act_samples=low_act_samples\n",
    "            )\n",
    "            features.append(feature)\n",
    "\n",
    "    # Sort features by index to maintain order\n",
    "    features.sort(key=lambda x: x.index)\n",
    "\n",
    "    # Extract labels and ids for easy reference\n",
    "    autointerp_feature_labels = [f.label for f in features]\n",
    "    autointerp_feature_ids = [f.index for f in features]\n",
    "\n",
    "    return features, autointerp_feature_labels, autointerp_feature_ids\n",
    "\n",
    "# Load features\n",
    "feature_dir = \"../feature_extraction/features/20241203_021311\"\n",
    "features, autointerp_feature_labels, autointerp_feature_ids = load_features(feature_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def prepare_dataset(sentences_file, embeddings_file, sae, autointerp_feature_ids=None, feature_registry_file=\"feature_registry.npy\", label_column='label', text_key=\"text\", split_sentences=True):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(sentences_file)\n",
    "    \n",
    "    # Create MiniPileDataset\n",
    "    mini_pile_dataset = MiniPileDataset(sentences_file, embeddings_file, key=text_key)\n",
    "    \n",
    "    # Featurize data\n",
    "    try:\n",
    "        X = np.memmap(\n",
    "            feature_registry_file,\n",
    "            dtype=\"float32\",\n",
    "            mode=\"r\",\n",
    "            shape=(sae.encoder.weight.shape[0], len(mini_pile_dataset.sentences)),\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        X = sae_featurize_data(mini_pile_dataset, sae, output_file=feature_registry_file)\n",
    "    \n",
    "    X = X.T\n",
    "    \n",
    "    # Apply num_features if specified\n",
    "    if autointerp_feature_ids is not None:\n",
    "        X = X[:, autointerp_feature_ids]\n",
    "    \n",
    "    y = np.where(df[label_column] == 'ham', 0, 1)\n",
    "    \n",
    "    if split_sentences:\n",
    "        X_split = []\n",
    "        y_split = []\n",
    "        for i, text in enumerate(df[text_key]):\n",
    "            sentences = sent_tokenize(text)\n",
    "            X_split.extend([X[i]] * len(sentences))\n",
    "            y_split.extend([y[i]] * len(sentences))\n",
    "        X = np.array(X_split)\n",
    "        y = np.array(y_split)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = \"../data_preparation/data/spam_messages_train.csv\"\n",
    "embeddings_file = \"../data_preparation/embedding_chunks/embedded_chunks/spam_messages_train_20241106_234743/embeddings.npy\"\n",
    "X_train, y_train = prepare_dataset(sentences_file, embeddings_file, sae, autointerp_feature_ids=autointerp_feature_ids, feature_registry_file=\"feature_registry_train_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = \"../data_preparation/data/spam_messages_val.csv\"\n",
    "embeddings_file = \"../data_preparation/embedding_chunks/embedded_chunks/spam_messages_val_20241107_005540/embeddings.npy\"\n",
    "X_val, y_val = prepare_dataset(sentences_file, embeddings_file, sae, autointerp_feature_ids=autointerp_feature_ids, feature_registry_file=\"feature_registry_val_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = \"../data_preparation/data/spam_messages_test.csv\"\n",
    "embeddings_file = \"../data_preparation/embedding_chunks/embedded_chunks/spam_messages_test_20241107_005747/embeddings.npy\"\n",
    "X_test, y_test = prepare_dataset(sentences_file, embeddings_file, sae, autointerp_feature_ids=autointerp_feature_ids, feature_registry_file=\"feature_registry_test_all.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class FeatureMixer:\n",
    "  def __init__(self, feature_group):\n",
    "    self.feature_group = feature_group\n",
    "\n",
    "  def grid(self, k_features_per_combo: int =2):\n",
    "    \"\"\"Perform a grid search over all possible combinations of features\"\"\"\n",
    "\n",
    "    # Get all possible combinations of features\n",
    "    return list(combinations(self.feature_group, k_features_per_combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Feature(index=166, label='Formal professional correspondence', attributes='formal language and structure, reference to organizational context, complete and structured sentences, calls to action or responses', reasoning='Upon analyzing both sets of samples, the texts from the first set consistently display elements of formality, official language, and often contain organizational or professional context. This includes mentions of formal titles, structured communication styles, and references to institutional practices. In contrast, the texts from the second set are casual, informal, and often contain unfinished thoughts or informal language. Moreover, the first set often includes complete structured sentences and explicit calls to action, such as invitations or requests for responses, which are absent in the second set.', density=0.004195095938602364, confidence=20.0, high_act_samples=[FeatureSample(text='dear sir / madam , my name is ahmed abdalla , director and board member , transparency international , kenya .', act=0.3816414773464203), FeatureSample(text='dear sir / madam , my name is ahmed abdalla , director and board member , transparency international , kenya .', act=0.3816414177417755), FeatureSample(text='the procedure is very simple : - apply officially to the director of operation global security company pty accra - ghana , for the release of consignment no .', act=0.34878942370414734), FeatureSample(text='evening , landlord : ) sige', act=0.3343393802642822), FeatureSample(text='open ( url , \" cbexitwindow \" , windowprops ) ; } } / / the cookie functions follow .', act=0.32045334577560425), FeatureSample(text='awaiting your urgent response .', act=0.3121907413005829), FeatureSample(text='thank you for your prompt attention to this matter and your co - operation in helping us maintain the integrity of our customers accounts .', act=0.29583150148391724), FeatureSample(text='192 ] ) by mta 3 .', act=0.2850295901298523), FeatureSample(text='box 91123 seattle , wa 98111 - 9223 or click here to read our privacy policy need customer support ?', act=0.272222638130188), FeatureSample(text='box 91123 seattle , wa 98111 - 9223 or click here to read our privacy policy need customer support ?', act=0.2722201645374298), FeatureSample(text='as our existing businesses grow and new businesses are created , ease of movement and development of our top talent becomes essential to our success .', act=0.26872536540031433), FeatureSample(text='low voltage * office * home * yard * patio * parking 12 / 24 volt audio & video equipment , computer monitoring video control & backup tapes set up and mounting , electro - optical assemblies & subsystems .', act=0.2660469710826874), FeatureSample(text='special forces units are concentrating on intelligence gathering and targeting key bin ladin installations , as well as attempting to locate bin ladin himself .', act=0.2617926001548767), FeatureSample(text='to join this professional gathering , please visit the website at : http : / / delson .', act=0.2569895088672638), FeatureSample(text='- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - our membership faq q .', act=0.25678643584251404), FeatureSample(text='𝑴𝒂𝒏𝒚 𝒈𝒊𝒓𝒍𝒔 𝒘𝒂𝒏𝒕 𝒕𝒐 𝒃𝒆 𝒂 𝒎𝒐𝒅𝒆𝒍 𝒂𝒏𝒅 𝑰 𝒘𝒂𝒏𝒕 𝒕𝒐 𝒃𝒆 𝒂 𝒓𝒐𝒍𝒆 𝒎𝒐𝒅𝒆𝒍', act=0.25615832209587097), FeatureSample(text='it is our great pleasure to inform you the grand opening of our hotel reservation web site www .', act=0.25414764881134033), FeatureSample(text='aggressor .', act=0.25398582220077515), FeatureSample(text='com if you wish to know more about our privacy policies please go to http : / / www .', act=0.251164048910141), FeatureSample(text='attorney who successfully prosecuted both the 1993 world trade center terrorists and the bin laden accomplices in the 1998 african embassy bombings .', act=0.23677200078964233)], low_act_samples=[FeatureSample(text='9 % in the past year , finishing ahead of only lehman brothers holdings inc .', act=0.0), FeatureSample(text='now you can go very wrong .', act=0.0), FeatureSample(text=\"assuming you qualify , we ' ll pick up the entire tab for you to visit our corporate offices in sunny san diego .\", act=0.0), FeatureSample(text='bank of boston , chase , chemical , citibank , they all started rallying .', act=0.0), FeatureSample(text='- save stellular over 75 % - total confident formicary iaiity - worldwide shlpp unworkmanlike lng - over 5 miili catalog on customers in 150 countries have a nice da riflegreen y !', act=0.0), FeatureSample(text=\"' there ' s really not a lot of overlap in assets , ' ' he said .\", act=0.0), FeatureSample(text='rs 1298 free shipping and cod all over india whatsapp for any order 9953977698 womens cateye sunglass description it has 1 piece of sunglasses material lens polycarbonate frame metal size free size', act=0.0), FeatureSample(text=\"3 bn , compared with enron ' s market value of $ 3 .\", act=0.0), FeatureSample(text=\"Don't do a masters as can't do this ever again!\", act=0.0), FeatureSample(text='sorry about earlier putting out firesare you around to talk after 9 or do you actually have a life lol', act=0.0), FeatureSample(text='charming lonely wiv 3 vs are un happy , make them happy each day another one !', act=0.0), FeatureSample(text='180 by 220 .', act=0.0), FeatureSample(text='i suggested that we have more of a strategic relationship in mine ( enron / stanford ) and he agreed to that as well .', act=0.0), FeatureSample(text='those factors include , but are not limited to : a limited operating history , a nominal cash position , nominal revenue in its most recent quarter , an accumulated deficit since its inception , a negative net worth , a going concern opinion from its auditor , a failure to make maintenance payments on it us patents , management believes it will not be able to complete its audited statments which will , if not rectified , eventually lead to a delisting of the stock from the bulletin board .', act=0.0), FeatureSample(text='sent : thu 1 / 3 / 2002 9 : 20 am to : luce , laura cc : subject : fw : remote offices laura , i understand that the metals group has asked to keep the chicago office open until mar 31 to wind things down .', act=0.0), FeatureSample(text='cameron payne vince congratulations on your promotion hope the litigation lawyers are leaving you alone i m attaching a resume of a friend of mine cameron payne i don t know if you are looking for anyone but cameron is pretty special as you ll see from his resume call him or me if you re interested in talking to him i m forwarding his resume to fastow and whalley too in case they see a fit take care bob', act=0.0), FeatureSample(text=\"2001 new york times company dynegy ' s decision to walk away from enron leaves citigroup and j .\", act=0.0), FeatureSample(text='com click here to apply for a car loan today !', act=0.0), FeatureSample(text='sounds good .', act=0.0), FeatureSample(text='5 / 5 oo m ^ g 3 o piils 139 .', act=0.0)]),) 0.7106298472860979 0.6364637330688687 DecisionTreeClassifier(max_depth=1, min_samples_leaf=13033, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 7676/19900 [19:45<36:21,  5.60it/s]  "
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "# Grid search may take a while, you can curate the feature list to speed this process up significantly\n",
    "def train_tree(x, y, depth):\n",
    "  train_x, test_x, train_y, test_y = train_test_split(x, y, train_size=0.5, random_state=42)\n",
    "\n",
    "  # Create a nice regularized tree\n",
    "  model = tree.DecisionTreeClassifier(\n",
    "      max_depth=depth,\n",
    "      min_samples_leaf=len(train_x) // 20,\n",
    "      random_state=42\n",
    "  )\n",
    "\n",
    "  model.fit(train_x, train_y)\n",
    "\n",
    "  pred = model.predict(test_x)\n",
    "\n",
    "  # Calculate the f1 score of the model\n",
    "  accuracy = balanced_accuracy_score(test_y, pred)\n",
    "  score = f1_score(test_y, pred)\n",
    "\n",
    "  return model, pred, score, accuracy\n",
    "\n",
    "\n",
    "def find_best_combo(features, k_features_per_combo = 2):\n",
    "  combos = FeatureMixer(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "  best_combo = None\n",
    "  best_model = None\n",
    "  best_score = 0\n",
    "  best_accuracy = 0\n",
    "\n",
    "  MAX_WORKERS = 8\n",
    "\n",
    "  futures_list = []\n",
    "\n",
    "  with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    for combo in combos:\n",
    "      def _test_combo(combo):\n",
    "        def _select_feature_acts(combo, row):\n",
    "          output = []\n",
    "          for index, feature in enumerate(combo):\n",
    "            for feature_act in row:\n",
    "              if feature_act.feature.index == feature.index:\n",
    "                output.append(feature_act.activation)\n",
    "                break\n",
    "\n",
    "          return output\n",
    "\n",
    "        model, pred, score, accuracy = train_tree(X_train, y_train, depth=len(combo))\n",
    "\n",
    "        return model, pred, score, accuracy, combo\n",
    "\n",
    "      futures_list.append(executor.submit(_test_combo, combo))\n",
    "\n",
    "    for future in tqdm.tqdm(futures_list):\n",
    "      model, pred, score, accuracy, combo = future.result()\n",
    "\n",
    "      if score > best_score:\n",
    "        best_score = score\n",
    "        best_combo = combo\n",
    "        best_model = model\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "  return best_combo, best_score, best_model, best_accuracy\n",
    "\n",
    "\n",
    "best_combo_at_k = {}\n",
    "for i in range(2):\n",
    "  best_combo, best_score, best_model, best_accuracy = find_best_combo(features, k_features_per_combo = i + 1)\n",
    "  print(i + 1, best_combo, best_score, best_accuracy, best_model)\n",
    "  best_combo_at_k[i + 1] = (best_combo, best_score, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the decision tree\n",
    "def visualize_tree(tree_model, features, class_names=['negative', 'positive']):\n",
    "    import graphviz\n",
    "    dot_data = tree.export_graphviz(\n",
    "        tree_model, \n",
    "        out_file=None, \n",
    "        feature_names=[feature.label for feature in features],\n",
    "        class_names=class_names,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True\n",
    "    )\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyways let's look at the best overall tree\n",
    "BEST_TREE_INDEX = 3\n",
    "best_features = best_combo_at_k[BEST_TREE_INDEX][0]\n",
    "best_score = best_combo_at_k[BEST_TREE_INDEX][1]\n",
    "best_tree = best_combo_at_k[BEST_TREE_INDEX][2]\n",
    "\n",
    "# Visualize the tree\n",
    "print(best_tree)\n",
    "print(best_features)\n",
    "print(best_score)\n",
    "visualize_tree(best_tree, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5,\n",
       "                                          n_estimators=295, n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x771E617C0440),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x771E617C0440)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BorutaPy<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BorutaPy(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5,\n",
       "                                          n_estimators=295, n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x771E617C0440),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x771E617C0440)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=295,\n",
       "                       n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x771E617C0440)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=295,\n",
       "                       n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x771E617C0440)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight='balanced', max_depth=5,\n",
       "                                          n_estimators=295, n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x771E617C0440),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x771E617C0440)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "boruta_selector = BorutaPy(\n",
    "  RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\", max_depth=5),\n",
    "  n_estimators=\"auto\",\n",
    "  verbose=0,\n",
    "  random_state=1,\n",
    ")\n",
    "boruta_selector.fit(X_train[:,:200], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boruta_selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50,  41,   1,   2,   1,   2,  44,  19,   3,  77, 113,   2,  47,\n",
       "        66,  94,  48, 113,   1, 113,   1,   2,  69,   1,   1,   1,   1,\n",
       "         1,  15,   1,  44,  88,   1,   1,   1,   1,  99, 113,   1,   1,\n",
       "        30,  81,   1,  85,  65,  71,   1,  91,  54,   1,  46,   1,   1,\n",
       "        32,  28,   1,   1,   1, 105,   1,   1,   1, 103,  38,   1,  60,\n",
       "        20,   1,  82,   1, 104,  63,   1,  21,   1,   1,  53,  56,   1,\n",
       "         1,  40,   1,   1,   3, 113,  34,   1,  33,  77,   1,   1,   1,\n",
       "        15,  70,  34,   5,  84,  95,  44,   1,   1,  38, 113,   7,  83,\n",
       "         1,  17,  28,  26,  85,  60,  93, 113,  59,   1,   1,  15,  42,\n",
       "         7,  10,   1,   1,  52,  10,   3,  79,  75,   1,  36,  95,  71,\n",
       "       113,   1,   1,   1,  22,  91, 106,   1,  89,  67, 101,   1,  63,\n",
       "       102,  13, 113,  18, 113, 113,   1,   1,  98,   1,  90,   1,   1,\n",
       "         5, 113, 113,  74,  49, 113,   1,   1,  50,  77,  68,   1,   2,\n",
       "        23,  79,  25,   1,  37,  99,  56,  12,   1,   1,   1,   1,   1,\n",
       "        10,  58,   1,  31,  54,  73,   1,  97,  62,   1,   1,  27,   2,\n",
       "        23,  87,   1,   1,   1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boruta_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"../feature_extraction/features/20241106_222955\"\n",
    "\n",
    "def get_feature_labels_from_mask(mask):\n",
    "    import json\n",
    "    import os\n",
    "    from tabulate import tabulate\n",
    "    \n",
    "    feature_info = []\n",
    "    for i, is_selected in enumerate(mask):\n",
    "        if is_selected:\n",
    "            feature_file = os.path.join(features_folder, f\"feature_{i}.json\")\n",
    "            with open(feature_file) as f:\n",
    "                feature_data = json.load(f)\n",
    "                feature_info.append({\n",
    "                    'index': i,\n",
    "                    'label': feature_data['label'],\n",
    "                    'confidence': feature_data.get('confidence', 'N/A')\n",
    "                })\n",
    "    \n",
    "    # Print nicely formatted table\n",
    "    headers = ['Index', 'Label', 'Confidence']\n",
    "    table = [[info['index'], info['label'], info['confidence']] for info in feature_info]\n",
    "    print(tabulate(table, headers=headers, tablefmt='grid'))\n",
    "    \n",
    "    return [info['label'] for info in feature_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features:\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|   Index | Label                                        |   Confidence |\n",
      "+=========+==============================================+==============+\n",
      "|       4 | Contains contact information                 |           80 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      20 | Spam or promotional indication               |           26 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      21 | Fragmented, urgent, obfuscated text patterns |            6 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      39 | Text with special patterns and symbols       |           75 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      97 | Contains direct call to action               |           30 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     121 | Spam-like and promotional structure          |           30 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     122 | Financial gain discussion                    |           21 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     137 | Repetitive text sequences                    |           39 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     185 | Promotional or sensitive content presence    |           30 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     192 | Structured financial and web content         |           30 |\n",
      "+---------+----------------------------------------------+--------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Contains contact information',\n",
       " 'Spam or promotional indication',\n",
       " 'Fragmented, urgent, obfuscated text patterns',\n",
       " 'Text with special patterns and symbols',\n",
       " 'Contains direct call to action',\n",
       " 'Spam-like and promotional structure',\n",
       " 'Financial gain discussion',\n",
       " 'Repetitive text sequences',\n",
       " 'Promotional or sensitive content presence',\n",
       " 'Structured financial and web content']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSelected Features:\")\n",
    "get_feature_labels_from_mask(boruta_selector.support_weak_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok let's actually train it and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Will try 5 different max_depths and 3 different n_estimators\n",
      "Total combinations to try: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ee06fa7bc84d8fbb896e4ffc74cfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration Results (max_depth=10, n_estimators=10):\n",
      "Accuracy: 0.6544\n",
      "Precision: 0.9940\n",
      "Recall: 0.2747\n",
      "F1: 0.4304\n",
      "AUC-ROC: 0.7318\n",
      "\n",
      "Iteration Results (max_depth=10, n_estimators=50):\n",
      "Accuracy: 0.6546\n",
      "Precision: 0.9909\n",
      "Recall: 0.2760\n",
      "F1: 0.4317\n",
      "AUC-ROC: 0.7341\n",
      "\n",
      "Iteration Results (max_depth=10, n_estimators=100):\n",
      "Accuracy: 0.6560\n",
      "Precision: 0.9923\n",
      "Recall: 0.2785\n",
      "F1: 0.4349\n",
      "AUC-ROC: 0.7347\n",
      "\n",
      "Iteration Results (max_depth=20, n_estimators=10):\n",
      "Accuracy: 0.6584\n",
      "Precision: 0.9925\n",
      "Recall: 0.2835\n",
      "F1: 0.4410\n",
      "AUC-ROC: 0.7327\n",
      "\n",
      "Iteration Results (max_depth=20, n_estimators=50):\n",
      "Accuracy: 0.6569\n",
      "Precision: 0.9926\n",
      "Recall: 0.2802\n",
      "F1: 0.4370\n",
      "AUC-ROC: 0.7350\n",
      "\n",
      "Iteration Results (max_depth=20, n_estimators=100):\n",
      "Accuracy: 0.6570\n",
      "Precision: 0.9924\n",
      "Recall: 0.2805\n",
      "F1: 0.4374\n",
      "AUC-ROC: 0.7374\n",
      "\n",
      "Iteration Results (max_depth=30, n_estimators=10):\n",
      "Accuracy: 0.6563\n",
      "Precision: 0.9793\n",
      "Recall: 0.2828\n",
      "F1: 0.4389\n",
      "AUC-ROC: 0.7318\n",
      "\n",
      "Iteration Results (max_depth=30, n_estimators=50):\n",
      "Accuracy: 0.6552\n",
      "Precision: 0.9721\n",
      "Recall: 0.2828\n",
      "F1: 0.4381\n",
      "AUC-ROC: 0.7333\n",
      "\n",
      "Iteration Results (max_depth=30, n_estimators=100):\n",
      "Accuracy: 0.6556\n",
      "Precision: 0.9739\n",
      "Recall: 0.2831\n",
      "F1: 0.4386\n",
      "AUC-ROC: 0.7339\n",
      "\n",
      "Iteration Results (max_depth=50, n_estimators=10):\n",
      "Accuracy: 0.6555\n",
      "Precision: 0.9735\n",
      "Recall: 0.2830\n",
      "F1: 0.4385\n",
      "AUC-ROC: 0.7288\n",
      "\n",
      "Iteration Results (max_depth=50, n_estimators=50):\n",
      "Accuracy: 0.6561\n",
      "Precision: 0.9717\n",
      "Recall: 0.2848\n",
      "F1: 0.4405\n",
      "AUC-ROC: 0.7317\n",
      "\n",
      "Iteration Results (max_depth=50, n_estimators=100):\n",
      "Accuracy: 0.6554\n",
      "Precision: 0.9720\n",
      "Recall: 0.2833\n",
      "F1: 0.4387\n",
      "AUC-ROC: 0.7296\n",
      "\n",
      "Iteration Results (max_depth=100, n_estimators=10):\n",
      "Accuracy: 0.6556\n",
      "Precision: 0.9709\n",
      "Recall: 0.2841\n",
      "F1: 0.4396\n",
      "AUC-ROC: 0.7290\n",
      "\n",
      "Iteration Results (max_depth=100, n_estimators=50):\n",
      "Accuracy: 0.6556\n",
      "Precision: 0.9708\n",
      "Recall: 0.2841\n",
      "F1: 0.4395\n",
      "AUC-ROC: 0.7288\n",
      "\n",
      "Iteration Results (max_depth=100, n_estimators=100):\n",
      "Accuracy: 0.6556\n",
      "Precision: 0.9706\n",
      "Recall: 0.2841\n",
      "F1: 0.4395\n",
      "AUC-ROC: 0.7290\n",
      "\n",
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 10}\n",
      "Best Validation Metrics:\n",
      "ACCURACY: 0.6584\n",
      "PRECISION: 0.9925\n",
      "RECALL: 0.2835\n",
      "F1: 0.4410\n",
      "AUC_ROC: 0.7327\n",
      "Evaluation on Test Set:\n",
      "Accuracy: 0.6588\n",
      "Precision: 0.9878\n",
      "Recall: 0.2614\n",
      "F1: 0.4134\n",
      "AUC-ROC: 0.7431\n",
      "Confusion Matrix:\n",
      "[[37669   104]\n",
      " [23761  8411]]\n"
     ]
    }
   ],
   "source": [
    "from classifier_model import BinaryClassifierModel\n",
    "\n",
    "# Initialize model\n",
    "model = BinaryClassifierModel()\n",
    "\n",
    "# Train model\n",
    "model.train_model(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    use_feature_selection=False\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "model.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try it with a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Metrics:\n",
      "Accuracy: 0.6817\n",
      "Precision: 0.9637\n",
      "Recall: 0.2387\n",
      "F1: 0.3826\n",
      "AUC-ROC: 0.6811\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.6944\n",
      "Precision: 0.9498\n",
      "Recall: 0.2355\n",
      "F1: 0.3774\n",
      "AUC-ROC: 0.6744\n",
      "\n",
      "Top 10 Features with Highest Weights:\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|   Index | Label                                        |   Confidence |\n",
      "+=========+==============================================+==============+\n",
      "|      60 | Business and finance communication in Polish |           79 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      68 | Business and operational references          |           16 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      71 | Incomplete URL presence                      |           79 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      81 | Mentions Vikings and sports content          |           80 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|      89 | Finance and economics context                |           44 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     149 | Transactional and task-focused messages      |           18 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     162 | Investment and financial discussions         |           29 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     172 | Solicitation with call to action             |           27 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     179 | Structured and formal communication          |            5 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "|     184 | Text patterns with irregular punctuation     |           20 |\n",
      "+---------+----------------------------------------------+--------------+\n",
      "Feature 149 (Business and finance communication in Polish): weight = 20.0979\n",
      "Feature 81 (Business and operational references): weight = 9.5343\n",
      "Feature 162 (Incomplete URL presence): weight = 8.9212\n",
      "Feature 179 (Mentions Vikings and sports content): weight = 7.1494\n",
      "Feature 172 (Finance and economics context): weight = 6.1457\n",
      "Feature 89 (Transactional and task-focused messages): weight = -5.9840\n",
      "Feature 71 (Investment and financial discussions): weight = 5.5030\n",
      "Feature 68 (Solicitation with call to action): weight = 5.4426\n",
      "Feature 184 (Structured and formal communication): weight = 4.3077\n",
      "Feature 60 (Text patterns with irregular punctuation): weight = -4.2736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize scaler and model\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions on validation set\n",
    "y_pred_val = model.predict(X_val_scaled)\n",
    "y_pred_proba_val = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# Calculate validation metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred_val):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred_val):.4f}\")\n",
    "print(f\"F1: {f1_score(y_val, y_pred_val):.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_val, y_pred_proba_val):.4f}\")\n",
    "\n",
    "# Get predictions on test set\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "y_pred_proba_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate test metrics\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba_test):.4f}\")\n",
    "\n",
    "# Print feature indexes with the highest weights and their labels\n",
    "feature_weights = model.coef_[0]\n",
    "top_feature_indices = np.argsort(np.abs(feature_weights))[::-1][:10]  # Get top 10 feature indices\n",
    "print(\"\\nTop 10 Features with Highest Weights:\")\n",
    "\n",
    "# Create boolean mask for get_feature_labels_from_mask\n",
    "mask = np.zeros(len(feature_weights), dtype=bool)\n",
    "mask[top_feature_indices] = True\n",
    "\n",
    "# Get labels and print table with weights\n",
    "feature_labels = get_feature_labels_from_mask(mask)\n",
    "for idx, label in zip(top_feature_indices, feature_labels):\n",
    "    print(f\"Feature {idx} ({label}): weight = {feature_weights[idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
