{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import transformer_lens\n",
    "from tqdm import tqdm\n",
    "\n",
    "import argparse\n",
    "import transformer_lens\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from shared.utils import LogFeatureDensityHistogram, get_datetime_string\n",
    "\n",
    "from shared import (\n",
    "    SparseAutoencoder,\n",
    "    SparseAutoencoderConfig,\n",
    "    save_weights_with_description,\n",
    "    load_weights_with_description,\n",
    ")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "device1 = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sentences with the highest feature activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = 768\n",
    "sae = SparseAutoencoder(SparseAutoencoderConfig(d_model=embed_dims, d_sparse=8 * embed_dims, sparsity_alpha=0)).to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights with description: Model trained at time 1721516425.1045861 with parameters: batch_size = 1024,\n",
      "max_batch_size = 1000,\n",
      "sparsity = 1,\n",
      "lr = 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_weights = load_weights_with_description(os.path.join(\"./weights\", \"sae_weights.pth\"))\n",
    "sae.load_state_dict(sae_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_stored_sentences(sentences, top_k = 50):\n",
    "  # assume sentences is (feature activation, sentence)\n",
    "  # Keep the lowest and highest top_k feature activations\n",
    "  sentences.sort()\n",
    "\n",
    "  if len(sentences) < 2 * top_k:\n",
    "    return sentences\n",
    "\n",
    "  new_sentences = sentences[:top_k] + sentences[-top_k:]\n",
    "  return new_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "mlp_layer = 5\n",
    "gpt_model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "# Load in the dataset\n",
    "ds = load_dataset(\"JeanKaddour/minipile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sentences = [[] for i in range(8 * embed_dims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 1/10000 [04:39<775:55:35, 279.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(f_by_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     27\u001b[0m   feature_sentences[i]\u001b[38;5;241m.\u001b[39mappend((f_by_feature[i], sent))\n\u001b[0;32m---> 28\u001b[0m   feature_sentences[i] \u001b[38;5;241m=\u001b[39m \u001b[43mprune_stored_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_sentences\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mprune_stored_sentences\u001b[0;34m(sentences, top_k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprune_stored_sentences\u001b[39m(sentences, top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# assume sentences is (feature activation, sentence)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# Keep the lowest and highest top_k feature activations\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   \u001b[43msentences\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentences) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m top_k:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentences\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_collection = None\n",
    "mode = \"test\"\n",
    "pbar = tqdm(range(len(ds[mode])), desc=\"Processing\")\n",
    "count = 0\n",
    "for sample in ds[mode]:\n",
    "  pbar.update(1)\n",
    "  count += 1\n",
    "  if count > 50:\n",
    "    break\n",
    "\n",
    "  # Break into sentences and find the activations\n",
    "  sample_sentences = sample[\"text\"].split(\".\")\n",
    "  for sent in sample_sentences:\n",
    "\n",
    "    logits, activations = gpt_model.run_with_cache(sent)\n",
    "\n",
    "    mlp_out = activations.cache_dict[f\"blocks.{mlp_layer}.hook_mlp_out\"].to(device1) # example MLP output, shape: (1, # samples, # dim)\n",
    "\n",
    "    y, f, loss, reconstruction_loss = sae(mlp_out, True)\n",
    "\n",
    "    # print(f.shape)\n",
    "\n",
    "    f_by_feature = torch.max(f, dim = 1).squeeze(0)\n",
    "    # print(f_by_feature.shape)\n",
    "\n",
    "    for i in range(f_by_feature.shape[0]):\n",
    "      feature_sentences[i].append((f_by_feature[i], sent))\n",
    "      feature_sentences[i] = prune_stored_sentences(feature_sentences[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0f780d5e244cdeba55c68ddd48a18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Input:', placeholder='Enter text here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25390e4ede26464ea45ac0574a1a339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='1', description='Feature Index:', placeholder='Enter feature index here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c996dcd62a4bf4b0740507e53d827c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Description:', disabled=True, layout=Layout(height='auto', width='auto'), plac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc104819425456ca688b316dc07f449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from transformers import GPT2Tokenizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def clean_token(token):\n",
    "    return token.replace(\"Ġ\", \" \")\n",
    "\n",
    "def highlight_text(text, activations):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    activations = activations[1:]\n",
    "    max_activation = max(activations)\n",
    "    highlighted_text = \"\"\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        token = clean_token(tokens[i])\n",
    "        opacity = activations[i] / max_activation if max_activation > 0 else 0\n",
    "        highlighted_text += f'<span style=\"background-color: rgba(255, 0, 255, {opacity})\">{token}</span>'\n",
    "    return highlighted_text\n",
    "\n",
    "def on_text_submit(change):\n",
    "    input_text = text_input.value\n",
    "    feature_index = int(feature_index_input.value)\n",
    "    if input_text == \"\":\n",
    "        return\n",
    "\n",
    "    # Load feature description\n",
    "    feature_file_path = os.path.join(\"./features\", f\"feature_{feature_index}.json\")\n",
    "    with open(feature_file_path, \"r\") as feature_file:\n",
    "        feature_data = json.load(feature_file)\n",
    "        feature_description.value = feature_data.get(\"label\", \"No description available.\")\n",
    "\n",
    "    logits, activations = gpt_model.run_with_cache(input_text)\n",
    "    mlp_out = activations.cache_dict[f\"blocks.{mlp_layer}.hook_mlp_out\"].to(device1)\n",
    "    y, f, loss, reconstruction_loss = sae(mlp_out, True)\n",
    "    highlighted_html = highlight_text(input_text, f[0, :, feature_index])\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(HTML(highlighted_html))\n",
    "\n",
    "text_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter text here...',\n",
    "    description='Input:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "feature_index_input = widgets.Text(\n",
    "    value='1',\n",
    "    placeholder='Enter feature index here...',\n",
    "    description='Feature Index:',\n",
    "    disabled=False\n",
    ")\n",
    "feature_description = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Feature description will appear here...',\n",
    "    description='Description:',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "text_input.observe(on_text_submit, names='value')\n",
    "feature_index_input.observe(on_text_submit, names='value')\n",
    "display(text_input)\n",
    "display(feature_index_input)\n",
    "display(feature_description)\n",
    "display(output_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "sae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
