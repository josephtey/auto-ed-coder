{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f159a2b",
   "metadata": {},
   "source": [
    "import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e17e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils.models import MiniPileDataset\n",
    "from utils.interp import count_non_zero_feature_activations, plot_feature_activation_histogram\n",
    "import os\n",
    "\n",
    "# Enable automatic reloading of modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the OpenAI API key from the environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea26c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the pickle file\n",
    "import pickle \n",
    "from utils.sae import SparseAutoencoder, SparseAutoencoderConfig\n",
    "import json\n",
    "\n",
    "# load the dataset\n",
    "file_name = \"files/all_sentences_with_embeddings_20240707_132959.pkl\"\n",
    "with open(file_name, \"rb\") as f:\n",
    "    mini_pile_dataset = pickle.load(f)\n",
    "\n",
    "# Load the configuration from the JSON file\n",
    "config_path = \"sae/20240708_195600_config.json\"\n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Load the pre-trained model from the pickle file\n",
    "sae_config = SparseAutoencoderConfig(d_model=config[\"dimensions\"], d_sparse=8 * config[\"dimensions\"], sparsity_alpha=config[\"sparsity_alpha\"])\n",
    "model = SparseAutoencoder(sae_config)\n",
    "model_path = \"sae/20240708_195600_sae.pkl\"\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_state_dict = pickle.load(f)\n",
    "    model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075f11f",
   "metadata": {},
   "source": [
    "interpret the feature activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60331aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Non-Zero Elements for first 100 samples: 12.8100004196167\n"
     ]
    }
   ],
   "source": [
    "count_non_zero_feature_activations(model, mini_pile_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f29946",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_activation_histogram(model, mini_pile_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a5c60",
   "metadata": {},
   "source": [
    "automated interp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.ai import OpenAIClient\n",
    "from utils.features import Feature, FeatureSample\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "# make folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"features/sae_features_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "ai = OpenAIClient(openai_api_key)\n",
    "\n",
    "n = len(mini_pile_dataset)\n",
    "feature_registry = np.zeros((config[\"dimensions\"] * 8, n))\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "  embedding = mini_pile_dataset.embeddings[i]\n",
    "  feature_activations = model.forward(embedding)[1]\n",
    "  feature_registry[:, i] = feature_activations.detach().numpy()\n",
    "    \n",
    "for index, feature in enumerate(feature_registry):\n",
    "    feature_samples = [FeatureSample(text=mini_pile_dataset.sentences[i], act=value) for i, value in enumerate(feature)]\n",
    "    feature_samples.sort(key=lambda x: x.act, reverse=True)\n",
    "\n",
    "    high_act_samples = feature_samples[:50]\n",
    "    low_act_samples = feature_samples[-50:]\n",
    "\n",
    "    try:\n",
    "        interpetation = ai.get_interpretation(high_act_samples, low_act_samples)\n",
    "        label = interpetation[\"label\"]\n",
    "        reasoning = interpetation[\"reasoning\"]\n",
    "        attributes = interpetation[\"attributes\"]\n",
    "    \n",
    "        high_act_score = ai.score_interpretation(high_act_samples, attributes)['percent']\n",
    "        low_act_score = ai.score_interpretation(low_act_samples, attributes)['percent']\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping feature due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "    labelled_feature = Feature(\n",
    "       index=index, \n",
    "       label=label, \n",
    "       attributes=attributes, \n",
    "       reasoning=reasoning, \n",
    "       confidence=abs(high_act_score - low_act_score), \n",
    "       density=(np.count_nonzero(feature) / len(feature)),\n",
    "       high_act_samples=high_act_samples,\n",
    "       low_act_samples=low_act_samples,\n",
    "    )\n",
    "\n",
    "    # write this feature\n",
    "    with open(os.path.join(folder_name, f\"feature_{index}.json\"), \"w\") as json_file:\n",
    "        json.dump(labelled_feature.dict(), json_file, indent=4)\n",
    "    \n",
    "    # print processed feature\n",
    "    print(f\"Processed feature {index}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2e0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
